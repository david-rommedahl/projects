{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from copy import deepcopy\n",
    "from typing import Literal, Any\n",
    "\n",
    "from pydantic import (\n",
    "    AliasChoices,\n",
    "    AliasPath,\n",
    "    AnyHttpUrl,\n",
    "    BaseModel,\n",
    "    ConfigDict,\n",
    "    Field,\n",
    "    field_serializer,\n",
    "    field_validator,\n",
    "    model_serializer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of Parsing models in the PIA rag-data-uploader package. The parsing models are based on Pydantic and their main functionality is to extract data from potentially nested fields and ensure that their values follow a set format.\n",
    "\n",
    "#### Throughout this notebook we will use the following dummy document to illustrate the function of these parsing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_document = {\n",
    "    \"page_content\": \"Random text for this dummy document.\",\n",
    "    \"metadata\": {\n",
    "        \"source\": \"1/DUMMY-DUMMY DUMMY DUMMY\",\n",
    "        \"seq_num\": 1,\n",
    "        \"book_id\": \"DUMMY\",\n",
    "        \"book_number\": \"DUMMY-DUMMY\",\n",
    "        \"book_title\": \"DUMMY\",\n",
    "        \"book_edition\": \"DUMMY\",\n",
    "        \"book_alt_title\": \"\",\n",
    "        \"book_pdf\": \"DUMMY-DUMMY\",\n",
    "        \"book_view_permission\": \"DUMMY\",\n",
    "        \"book_audience\": \"DUMMY\",\n",
    "        \"book_date\": \"2022-11-10\",\n",
    "        \"doctype\": \"DUMMY\",\n",
    "        \"date\": \"\",\n",
    "        \"view_permission\": \"DUMMY\",\n",
    "        \"inferred_products\": [],\n",
    "        \"cpi_folders\": None,\n",
    "        \"pia_graphs\": None,\n",
    "        \"builder_meta\": {\n",
    "            \"identity\": \"DUMMY-DUMMY\",\n",
    "            \"document_number\": \"DUMMY-DUMMY\",\n",
    "            \"decimal_class\": \"DUMMY\",\n",
    "            \"revision\": \"DUMMY\",\n",
    "            \"dxp_filename\": \"DUMMY-DUMMY.dxp\",\n",
    "            \"eridoc_document_number\": \"1/DUMMY-DUMMY DUMMY DUMMY\",\n",
    "            \"elex_filename\": \"DUMMY-DUMMY.DUMMY.html\",\n",
    "            \"title\": \"DUMMY\",\n",
    "            \"document_type\": \"DUMMY Guide\",\n",
    "            \"category_tree\": \"Category does not exist\",\n",
    "            \"library_url\": \"https://DUMMY.DUMMY.DUMMY.com/DUMMY?LI=DUMMY/DUMMY+DUMMY+DUMMY+DUMMY\",\n",
    "            \"document_url\": \"https://DUMMY.DUMMY.DUMMY.com/DUMMY?LI=DUMMY/DUMMY+DUMMY+DUMMY+DUMMY&FN=DUMMY-DUMMY.DUMMY.html\",\n",
    "            \"content_from_libraries\": [\n",
    "                {\n",
    "                    \"identity\": \"DUMMY/DUMMY DUMMY DUMMY DUMMY\",\n",
    "                    \"title\": \"DUMMY DUMMY DUMMY.DUMMY.2\",\n",
    "                    \"date\": \"2024-04-03\",\n",
    "                }\n",
    "            ],\n",
    "            \"external_document_url\": \"https://DUMMY.DUMMY.DUMMY.com/DUMMY?LI=DUMMY/DUMMY+DUMMY+DUMMY+DUMMY&FN=DUMMY-DUMMY.DUMMY.html\",\n",
    "        },\n",
    "        \"chunk_token_size\": 887,\n",
    "    },\n",
    "    \"embedding\": [\n",
    "        0.0048415693,\n",
    "        0.039551053,\n",
    "        0.00871117,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The idea of these parsing models is to simplify parsing document sources within the RegenX framework, and to allow the user to create their own parsing models in a flexible way. For this reason, a base parsing model called `RegenXBaseParsingModel`, which has the mandatory fields of the RegenX documents, has been created and can be imported by `from rag_data_uploader.utils.parsing_models import RegenXBaseParsingModel`. This is the parsing model that all other parsing models within the framework should inherit from, and it is equivalent to what can be seen in the next cell.\n",
    "\n",
    "#### If we use this model to parse the dummy document, we will see that only the three fields which are defined in the model are kept. The model keeps `page_content` but now calls it `content`. It also keeps the `embedding` field and adds a new field called `content_type` which is a field which is required by Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegenXBaseParsingModel(BaseModel):\n",
    "    \"\"\"Base parsing model with required fields.\n",
    "\n",
    "    Any parsing model should inherit from this base model. Desired metadata fields,\n",
    "    field validators and serializers should be added to the child class.\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = ConfigDict(extra=\"ignore\")\n",
    "\n",
    "    content: str = Field(validation_alias=AliasChoices(\"page_content\", \"content\"))\n",
    "    content_type: Literal[\"text\"] = \"text\"\n",
    "    embedding: list[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Random text for this dummy document.',\n",
       " 'content_type': 'text',\n",
       " 'embedding': [0.0048415693, 0.039551053, 0.00871117]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegenXBaseParsingModel.model_validate(dummy_document).model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To illustrate what happens if a field does not follow the specified schema or if a required field is missing, we will modify the dumy document and parse it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_document = deepcopy(dummy_document)\n",
    "faulty_document[\"page_content\"] = 1\n",
    "_ = faulty_document.pop(\"embedding\")\n",
    "RegenXBaseParsingModel.model_validate(faulty_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```bash\n",
    "ValidationError: 2 validation errors for RegenXBaseParsingModel\n",
    "page_content\n",
    "  Input should be a valid string [type=string_type, input_value=1, input_type=int]\n",
    "    For further information visit https://errors.pydantic.dev/2.5/v/string_type\n",
    "embedding\n",
    "  Field required [type=missing, input_value={'page_content': 1, 'meta...chunk_token_size': 887}}, input_type=dict]\n",
    "    For further information visit https://errors.pydantic.dev/2.5/v/missing\"\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that Pydantic raises two validation errors, one for a faulty input and one for a missing field. This is what happens if the documents that are passed into the parsing model does not conform to the specified schema.\n",
    "\n",
    "#### As mentioned before, the idea of the parsing models is that they should function as flexible pre-processing helpers and that the user can create their own parsers by inheriting from the base parser. A parsing model which inherits from the base parsing model has already been created for the RegenX CPI documents. This can be imported as `from rag_data_uploader.utils.parsing_models import RegenXParsingModelCPI`. This contains the necessary fields which have been specified for the RegenX framework CPI use case and is equivalent to the model seen below.\n",
    "\n",
    "#### Note that this model uses a helper function called `metadata_field`, which helps tell the model where to look for field names in a potentially nested JSON object. Also note that the model uses a sub-model called `ContentFromLibraries` which helps parse a nested field which is itself a JSON object. This is the preferred way to handle fields which are not simple types or lists of types. This way we can parse and typecheck even the values of these nested fields. Note that the `RegenXParsingModelCPI` has a required field called `chapter_title`. This was required by the RegenX framework standard at creation time of the repo. This might change going forward though, and modifications might be needed. For now, we will simply add such a field to the dummy document in order to parse it with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_field(field_name: str, **kwargs) -> Field:\n",
    "    \"\"\"Helper function which constructs paths for a given metadata field.\n",
    "\n",
    "    This helper function returns a pydantic.Field object, and it takes any\n",
    "    arguments that the Field argument takes. If 'validation_alias' is specified\n",
    "    it is dropped.\n",
    "    \"\"\"\n",
    "    kwargs.pop(\"validation_alias\", None)\n",
    "    return Field(\n",
    "        validation_alias=AliasChoices(\n",
    "            field_name,\n",
    "            AliasPath(\"metadata\", field_name),\n",
    "            AliasPath(\"metadata\", \"builder_meta\", field_name),\n",
    "        ),\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "class RegenXParsingModelCPI(RegenXBaseParsingModel):\n",
    "    \"\"\"Parsing model for RegenX CPI data.\n",
    "\n",
    "    This model inherits from the base parsing model and extends it\n",
    "    with required metadata fields for the RegenX CPI schema.\n",
    "    \"\"\"\n",
    "\n",
    "    class ContentFromLibraries(BaseModel):\n",
    "        \"\"\"Sub-model to be used for nested dictionary within CPI document.\"\"\"\n",
    "\n",
    "        model_config = ConfigDict(extra=\"ignore\")\n",
    "\n",
    "        identity: str\n",
    "        title: str\n",
    "        date: datetime.date\n",
    "\n",
    "        @field_serializer(\"date\")\n",
    "        def serialize_date(self, v: datetime.date) -> str:\n",
    "            return str(v)\n",
    "\n",
    "    source: str = metadata_field(\"source\")\n",
    "    document_number: str = metadata_field(\"document_number\")\n",
    "    identity: str = metadata_field(\"identity\")\n",
    "    chapter_title: str | list[str] = metadata_field(\"chapter_title\")\n",
    "    revision: str = metadata_field(\"revision\")\n",
    "    title: str = metadata_field(\"title\")\n",
    "    document_type: str = metadata_field(\"document_type\")\n",
    "    category_tree: str = metadata_field(\"category_tree\")\n",
    "    document_url: AnyHttpUrl = metadata_field(\"document_url\")\n",
    "    library_url: AnyHttpUrl = metadata_field(\"library_url\")\n",
    "    external_document_url: AnyHttpUrl = metadata_field(\"external_document_url\")\n",
    "    content_from_libraries: list[ContentFromLibraries] = metadata_field(\"content_from_libraries\")\n",
    "    eridoc_document_number: str = metadata_field(\"eridoc_document_number\")\n",
    "\n",
    "    @field_validator(\"chapter_title\")\n",
    "    @classmethod\n",
    "    def validate_chapter_title(cls, v: str | list[str]) -> str:\n",
    "        \"\"\"Ensures that chapter_title is a string instead of a list of strings.\"\"\"\n",
    "        if isinstance(v, list):\n",
    "            if len(v) == 1:\n",
    "                return next(iter(v))\n",
    "            else:\n",
    "                raise ValueError\n",
    "        return v\n",
    "\n",
    "    @field_serializer(\"document_url\", \"library_url\", \"external_document_url\")\n",
    "    def serialize_url(self, v: AnyHttpUrl) -> str:\n",
    "        \"\"\"URL type is not JSON serializable.\"\"\"\n",
    "        return str(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Random text for this dummy document.',\n",
       " 'content_type': 'text',\n",
       " 'embedding': [0.0048415693, 0.039551053, 0.00871117],\n",
       " 'source': '1/DUMMY-DUMMY DUMMY DUMMY',\n",
       " 'document_number': 'DUMMY-DUMMY',\n",
       " 'identity': 'DUMMY-DUMMY',\n",
       " 'chapter_title': 'DUMMY',\n",
       " 'revision': 'DUMMY',\n",
       " 'title': 'DUMMY',\n",
       " 'document_type': 'DUMMY Guide',\n",
       " 'category_tree': 'Category does not exist',\n",
       " 'document_url': 'https://dummy.dummy.dummy.com/DUMMY?LI=DUMMY/DUMMY+DUMMY+DUMMY+DUMMY&FN=DUMMY-DUMMY.DUMMY.html',\n",
       " 'library_url': 'https://dummy.dummy.dummy.com/DUMMY?LI=DUMMY/DUMMY+DUMMY+DUMMY+DUMMY',\n",
       " 'external_document_url': 'https://dummy.dummy.dummy.com/DUMMY?LI=DUMMY/DUMMY+DUMMY+DUMMY+DUMMY&FN=DUMMY-DUMMY.DUMMY.html',\n",
       " 'content_from_libraries': [{'identity': 'DUMMY/DUMMY DUMMY DUMMY DUMMY',\n",
       "   'title': 'DUMMY DUMMY DUMMY.DUMMY.2',\n",
       "   'date': '2024-04-03'}],\n",
       " 'eridoc_document_number': '1/DUMMY-DUMMY DUMMY DUMMY'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_document.update({\"chapter_title\": \"DUMMY\"})\n",
    "RegenXParsingModelCPI.model_validate(dummy_document).model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To create your own custom model, you should inherit from the `RegenXBaseParsingModel` and add the required fields and types. I would suggest using the helper function `metadata_field` to specify the field name as above and help with the potentially nested structure of the JSON objects. For more information on using Pydantic models as parsing models, check the [Pydantic documentation](https://docs.pydantic.dev/latest/concepts/models/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uploader-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
