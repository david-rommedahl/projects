{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import (\n",
    "    AnyHttpUrl,\n",
    "    BaseModel,\n",
    "    ConfigDict,\n",
    "    field_serializer,\n",
    ")\n",
    "from S3_helper.helper import S3\n",
    "\n",
    "from rag_data_uploader import OpensearchUploader\n",
    "from rag_data_uploader.utils.mappings import OSBaseMapping\n",
    "from rag_data_uploader.utils.parsing_models import RegenXBaseParsingModel, metadata_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()\n",
    "access_key = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "secret_key = os.getenv(\"MINIO_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New temporary parsing model for documents which are missing the chapter_title metadata field.\n",
    "class RegenXParsingModelCPI(RegenXBaseParsingModel):\n",
    "    \"\"\"Parsing model for RegenX CPI data.\"\"\"\n",
    "\n",
    "    class ContentFromLibraries(BaseModel):\n",
    "        identity: str\n",
    "        title: str\n",
    "        date: datetime.date\n",
    "\n",
    "        @field_serializer(\"date\")\n",
    "        def serialize_date(self, v: datetime.date) -> str:\n",
    "            return str(v)\n",
    "\n",
    "    source: str = metadata_field(\"source\")\n",
    "    document_number: str = metadata_field(\"document_number\")\n",
    "    identity: str = metadata_field(\"identity\")\n",
    "    # chapter_title: str | list[str] = metadata_field(\"chapter_title\")\n",
    "    revision: str = metadata_field(\"revision\")\n",
    "    title: str = metadata_field(\"title\")\n",
    "    document_type: str | None = metadata_field(\"document_type\")\n",
    "    category_tree: str = metadata_field(\"category_tree\")\n",
    "    document_url: AnyHttpUrl = metadata_field(\"document_url\")\n",
    "    library_url: AnyHttpUrl = metadata_field(\"library_url\")\n",
    "    external_document_url: AnyHttpUrl = metadata_field(\"external_document_url\")\n",
    "    content_from_libraries: list[ContentFromLibraries] = metadata_field(\"content_from_libraries\")\n",
    "    eridoc_document_number: str = metadata_field(\"eridoc_document_number\")\n",
    "\n",
    "    # @field_validator(\"chapter_title\")\n",
    "    # @classmethod\n",
    "    # def validate_chapter_title(cls, v: str | list[str]) -> str:\n",
    "    #     if isinstance(v, list):\n",
    "    #         if len(v) == 1:\n",
    "    #             return next(iter(v))\n",
    "    #         else:\n",
    "    #             raise ValueError\n",
    "    #     return v\n",
    "\n",
    "    @field_serializer(\"document_url\", \"library_url\", \"external_document_url\")\n",
    "    def serialize_url(self, v: AnyHttpUrl) -> str:\n",
    "        return str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special mapping class which excludes chapter_title\n",
    "class OSRegenXMappingCPI(OSBaseMapping):\n",
    "    model_config = ConfigDict(validate_default=True, extra=\"ignore\")\n",
    "\n",
    "    embedding: int = 1536\n",
    "    identity: str = \"keyword\"\n",
    "    source: str = \"keyword\"\n",
    "    document_number: str = \"keyword\"\n",
    "    revision: str = \"keyword\"\n",
    "    title: str = \"keyword\"\n",
    "    document_type: str = \"keyword\"\n",
    "    category_tree: str = \"keyword\"\n",
    "    document_url: str = \"keyword\"\n",
    "    library_url: str = \"keyword\"\n",
    "    external_document_url: str = \"keyword\"\n",
    "    content_from_libraries: dict[str, str] = {\n",
    "        \"identity\": \"keyword\",\n",
    "        \"title\": \"keyword\",\n",
    "        \"date\": \"keyword\",\n",
    "    }\n",
    "    eridoc_document_number: str = \"keyword\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use the S3 client class to download data for upload from Minio. First, we specify the date which should be downloaded. Note that this might be quite outdated by the time you read this.\n",
    "\n",
    "### After this, we use the client to download whatever files are not already present on the machine, and extract the folders containing the JSON objects that should be uploaded to the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2024-07-04\"\n",
    "s3_client = S3(access_key=access_key, secret_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in s3_client.list_files(f\"rag/{date}/\", \"sandbox\")]\n",
    "embedding_folders = list(\n",
    "    {Path(file).parent for file in files if Path(file).parent.name == \"AZOpenAI\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('rag/2024-07-04/mini-link_6651/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/power/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6654/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/rbs_series/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6291/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6691/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/router_6000/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/radio_dot_system/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6366/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6693/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/network_synchornization/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6692/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6371/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6262/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/5g_plugins/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6655/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/radio/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/nr_ran_cpi/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/ran_compute/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/enclosure/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/baseband_radio_node_cpi/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/integrated_site_solutions/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6694/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/fronthaul/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6251/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/ericsson_network_connection/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/antenna_system/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/lte_ran_cpi/embedding_output/AZOpenAI'),\n",
       " PosixPath('rag/2024-07-04/mini-link_6252/embedding_output/AZOpenAI')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_folders = [Path(\"rag/2024-07-04/radio/embedding_output/AZOpenAI\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(f\"../data/{date}\")\n",
    "if output_dir.exists():\n",
    "    existing_folders = [p.name for p in output_dir.glob(\"*\")]\n",
    "    folders_to_download = [\n",
    "        folder for folder in embedding_folders if folder.parts[2] not in existing_folders\n",
    "    ]\n",
    "else:\n",
    "    output_dir.mkdir()\n",
    "    folders_to_download = embedding_folders\n",
    "\n",
    "for folder in folders_to_download:\n",
    "    output_folder = output_dir / \"/\".join(folder.parts[2:])\n",
    "    s3_client.download_files(\n",
    "        s3_bucket_name=\"sandbox\", s3_folder_name=str(folder), local_folder_name=output_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_upload = [p for p in Path(output_dir).rglob(\"*AZOpenAI\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/2024-07-04/radio/embedding_output/AZOpenAI')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders_to_upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the relevant data has been downloaded and extracted, we use the uploader class from the `rag_data_uploader` library to upload the documents to the vector store. Note that this requires that the vector store is either running locally and can be reached on port 9200, or that we have port-forwarded the vector store to this port. Also note that you need to specify the credentials to the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://localhost:9200\"\n",
    "username = \"admin\"\n",
    "password = \"admin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL:  https://localhost:9200\n",
      "Response from document store at URL https://localhost:9200:  OK\n"
     ]
    }
   ],
   "source": [
    "mapping = OSRegenXMappingCPI()\n",
    "uploader = OpensearchUploader(url, username, password, allow_missing_fields=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders_to_upload:\n",
    "    errors = False\n",
    "    folder_name = folder.parts[3]\n",
    "    index = f\"regenx_data_{folder_name}_{date}\"\n",
    "    alias = f\"regenx_data_{folder_name}\"\n",
    "\n",
    "    print(\"Uploading: \", folder_name)\n",
    "    uploader.upload_from_folder(\n",
    "        folder,\n",
    "        index,\n",
    "        mapping=mapping,\n",
    "        parsing_model=RegenXParsingModelCPI,\n",
    "        alias=alias,\n",
    "        threading=False,\n",
    "        batch_size=0.9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After all of this, you should have successfully uploaded all of your data to the vector store. If any errors were encountered, it will be printed out at the end of the upload process, and a JSON file called `upload_errors.json` will be saved to the folder which this notebook is run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = httpx.get(f\"{uploader.url}/regenx*\", **uploader.req_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regenx_data_5g_plugins_2024-05-06',\n",
       " 'regenx_data_antenna_system_2024-05-06',\n",
       " 'regenx_data_baseband_radio_node_cpi_24.17_2024-04-30',\n",
       " 'regenx_data_enclosure_2024-05-06',\n",
       " 'regenx_data_ericsson_network_connection_2024-05-06',\n",
       " 'regenx_data_fronthaul_2024-05-06',\n",
       " 'regenx_data_integrated_site_solutions_2024-05-06',\n",
       " 'regenx_data_lte_ran_cpi_24.17_2024-04-30',\n",
       " 'regenx_data_mini-link_6251_2024-05-06',\n",
       " 'regenx_data_mini-link_6252_2024-05-06',\n",
       " 'regenx_data_mini-link_6262_2024-05-06',\n",
       " 'regenx_data_mini-link_6291_2024-05-06',\n",
       " 'regenx_data_mini-link_6366_2024-05-06',\n",
       " 'regenx_data_mini-link_6371_2024-05-06',\n",
       " 'regenx_data_mini-link_6651_2024-05-06',\n",
       " 'regenx_data_mini-link_6654_2024-05-06',\n",
       " 'regenx_data_mini-link_6655_2024-05-06',\n",
       " 'regenx_data_mini-link_6691_2024-05-06',\n",
       " 'regenx_data_mini-link_6692_2024-05-06',\n",
       " 'regenx_data_mini-link_6693_2024-05-06',\n",
       " 'regenx_data_mini-link_6694_2024-05-06',\n",
       " 'regenx_data_network_synchornization_2024-05-06',\n",
       " 'regenx_data_nr_ran_cpi_24.17_2024-04-30',\n",
       " 'regenx_data_power_2024-05-06',\n",
       " 'regenx_data_radio_2024-05-06',\n",
       " 'regenx_data_radio_2024-07-04',\n",
       " 'regenx_data_radio_dot_system_2024-05-06',\n",
       " 'regenx_data_ran_compute_2024-05-06',\n",
       " 'regenx_data_rbs_series_2024-05-06',\n",
       " 'regenx_data_router_6000_2024-05-06']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(res.json().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = httpx.delete(f\"{uploader.url}/regenx_data_radio_2024-05-06/_alias/regenx_data_radio\", **uploader.req_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader.index = \"regenx_data_radio_2024-05-06\"\n",
    "uploader.alias = 'regenx_data_radio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = uploader._find_alias_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regenx_data_radio_2024-07-04']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploader.indices_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_data_uploader.utils.regexes import INDEX_REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regenx_data_radio'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_REGEX.match(uploader.index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uploader-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
